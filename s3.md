## S3 (Simple Storage Service)

* S3 (Simple Storage Service) is a highly scalable, available, secure, and high-performance object storage service provided by Amazon Web Services (AWS).
* In simple terms, S3 functions like a cloud-based storage service similar to Dropbox or Google Drive, but with the extensive capabilities and integration of AWS.
* S3 is an object-based storage system, meaning it stores complete objects (files) with their metadata.

  ![image](https://github.com/user-attachments/assets/af9f0498-a8b3-4a84-a756-d88bcc36a9d7)

  * S3 is ideal for storing:
    * Application log files
    * Media assets such as images, videos, and audio files
    * Artifacts generated from CI/CD pipelines

* Buckets
  * Buckets are the containers in S3 where objects (files) are stored. Think of a bucket as a folder that groups related files.
  *  **Bucket name has to be unique across AWS.**

* Objects
  * An object in S3 consists of the file data and its metadata. Each object includes:
    * A key: a unique name for the file.
    * A value: the actual data of the file.
    * Additional properties such as version ID and metadata (if versioning is enabled).
   
![image](https://github.com/user-attachments/assets/ace0ead0-254b-4424-8c7e-8aa7ca1bc3d5)

* Flat File Structure
  * S3 utilizes a flat file structure, meaning there is no inherent concept of nested directories. While the AWS console may visually display folder-like groupings using prefixes, the underlying storage remains flat. For example, uploading files with keys like "music/song_one", "music/song_two", and "music/song_three" creates the illusion of a "music" folder.

![image](https://github.com/user-attachments/assets/ddf53c35-c2fb-4198-b4b6-229645052958)

* Data Durability and Availability
  * When you upload a file to S3, AWS replicates it across multiple servers and availability zones. This replication ensures high durability and availability, protecting your data even if a server or entire availability zone fails.

![image](https://github.com/user-attachments/assets/ec136ae9-1dc7-4b18-a03b-aac950118ec6)

* S3 Restrictions
  * S3 can store an unlimited number of objects.
  * The maximum size for a single object is 5 terabytes.
  * By default, each AWS account can create up to 100 buckets. This limit can be increased up to 1,000 by requesting a service limit increase.

## S3 Storage Classes

* **S3 Standard**
  * S3 Standard is the default storage class for AWS S3. When you upload a file without specifying a storage class, it is automatically stored as S3 Standard.
  * In this class, objects are automatically replicated across at least three Availability Zones (AZs), enabling the system to survive up to two simultaneous AZ failures.
  * This design ensures an impressive durability of 99.999999999% (11 nines).
  * Billed per gigabyte per month.
  * Low latency access with files available in milliseconds.
  * Support for public access (ideal for web application media files).
  * Charges for data egress; uploading data (ingress) is free.

* **S3 Standard-IA (Infrequent Access)**
  * S3 Standard-IA is designed for data that is accessed less frequently while still requiring rapid access when needed.
  * Similar to S3 Standard, it replicates data across at least three Availability Zones to ensure high durability.
  * However, it offers a lower storage cost for infrequently accessed data.
  * Lower per gigabyte storage rates compared to S3 Standard.
  * Maintains low latency for rapid data access.
  * Applies a retrieval fee on each data request along with a per-gigabyte egress charge.
  * Enforces a minimum duration charge of 30 days per object. If an object is deleted before 30 days, you are still charged for the full period.
  * Uses a minimum object size charge of 128 kilobytes (even a 1 KB file is billed as 128 KB).
 
* **S3 One Zone-IA (One Zone Infrequent Access)**
  * S3 One Zone-IA is similar to S3 Standard-IA, but stores data in a single Availability Zone instead of multiple zones, resulting in lower storage costs.
  * This makes it an attractive option for data that is infrequently accessed and does not require the added resiliency of multiple AZ replication.
  * Provides immediate, low latency access.
  * Supports public access similar to other S3 storage classes.
  * Applies charges for egress, retrieval, a minimum duration of 30 days, and a minimum size charge of 128 kilobytes.
  * Lacks multi-AZ replication, meaning that in the event of an AZ failure, your data could become inaccessible.
 
* **S3 Glacier Instant**
  * S3 Glacier Instant is part of the Glacier family and is designed for archiving data that is rarely accessed while providing rapid data retrieval.
  * Low-cost storage optimized for archival data.
  * Retrieval of data in milliseconds.
  * Lower per gigabyte charges compared to S3 Standard.
  * Data egress fees and additional retrieval fees apply.
  * A minimum duration charge of 90 days and a minimum size charge of 128 kilobytes per object.

* **S3 Glacier Flexible**
  * S3 Glacier Flexible is intended for data that is archived and does not require immediate access.
  * Unlike S3 Glacier Instant, objects stored in Glacier Flexible are not available instantly; a retrieval process similar to a "cold start" is necessary.
  * Consequently, direct public access to these objects is not supported.
  * Retrieval fees and a minimum duration charge of 90 days apply.
  * Enforces a minimum size charge of 40 kilobytes per object.
  * Offers three retrieval options based on speed:
    * Expedited (1–5 minutes)
    * Standard (3–5 hours)
    * Bulk (5–12 hours)

* **S3 Glacier Deep Archive**
  *  S3 Glacier Deep Archive provides the most cost-effective storage solution available for AWS S3.
  *  Like Glacier Flexible, objects stored in this class are not immediately available and must go through a retrieval process.
  *  This class is ideal for data that is rarely needed and can tolerate longer retrieval times.
  *  Charges include a per-gigabyte egress fee and a retrieval fee.
  *  A minimum duration charge of 180 days applies, along with a minimum size charge of 40 kilobytes per object.
  *  Retrieval options include:
     * Standard (within 12 hours)
     * Bulk (within 48 hours; the more cost-effective choice if immediate access isn’t critical)
  * Retrieved data is temporarily stored in S3 Standard-IA.

* **S3 Intelligent Tiering**
  * S3 Intelligent Tiering is a smart storage option for workloads with unpredictable access patterns.
  * This class automatically moves data between tiers to optimize storage costs based on changing usage patterns.
  * An additional monitoring and automation fee is applied per 1,000 objects alongside the underlying storage cost.

Choosing the Right Storage Class
* Selecting the appropriate storage class depends on your performance requirements and budget considerations.
* Use the following decision-making process to choose the correct AWS S3 storage class:

Determine if immediate access (within milliseconds) is necessary.
 * If yes, consider:
   * Frequent access: Choose S3 Standard.
   * Infrequent access:
     * Multi-AZ resilience needed: Choose S3 Standard-IA.
     * Single-AZ storage is sufficient: Choose S3 One Zone-IA.
 * If immediate access is not required:
   * For very rarely accessed data: Choose S3 Glacier Deep Archive.
   * For archival data with occasional access needs: Choose S3 Glacier Flexible.
  
 ![image](https://github.com/user-attachments/assets/7d1dbccd-a8c1-4450-b90c-da2a443c7ad2)

#### S3 Versioning

* Versioning is a bucket-level setting—it applies to every object stored in the bucket. A bucket can be in one of three states:
  * Unversioned (Default State) – Versioning is disabled.
  * Versioning Enabled – New versions of objects are recorded.
  * Versioning Suspended – Existing versions are kept, but new uploads do not receive version IDs.

* Deleting Objects with Versioning
  * When you delete an object without specifying a version ID while versioning is enabled, S3 adds a "delete marker" instead of permanently removing older versions.
  * This delete marker makes it appear as if the file is deleted, while previous versions remain intact.
  *  Removing the delete marker in the S3 console will restore the most recent previous version as the current version.

 * Suspended Versioning
   * All previous versions remain stored in the bucket.
   * New uploads receive a null version ID, effectively behaving as if versioning is disabled.
   * If you upload a new object with an existing key, it permanently replaces the current version while preserving the historical versions.
  
#### S3 ACL and Resource Policies
* When you create an S3 bucket, it starts in a locked-down state.
* By default, only the bucket creator—and the root user, who has full account access—can access it.
* Other AWS users within your account, public users, and users from other AWS accounts do not get access automatically.
* An S3 bucket policy determines which users have permission to access the bucket and specifies the operations they are authorized to perform.

**Bucket Policy Structure**

Bucket policies are written in JSON and generally include the following components:

* Version: Specifies the policy language syntax (e.g., "2012-10-17").
* Statement: Contains one or more policy statements. Each statement includes:
  * Sid: An optional statement identifier for reference.
  * Principal: The AWS user(s) or account(s) the policy applies to.
  * Effect: Indicates whether the policy allows or denies access.
  * Action: Specifies the allowed or denied actions.
  * Resource: Defines the ARN (Amazon Resource Name) of the bucket or its objects that the statement affects.

![image](https://github.com/user-attachments/assets/54525121-7aaf-4f35-90d8-2835a505fcda)

**Multiple Statements in a Bucket Policy**

![image](https://github.com/user-attachments/assets/e65e62b5-c2a7-4fe4-b42f-1613681b4b8a)

**Using Conditions in Bucket Policies**
Conditions in policies can further refine access rules. For example, you might restrict operations based on the user's source IP address. The following policy only allows actions from the 192.0.2.0/24 subnet:

![image](https://github.com/user-attachments/assets/f02039dc-7839-4750-bf1d-016a3aab9ff2)

**Public Access and Extra Security Measures**
AWS provides a "Block Public Access" setting as an extra security measure to prevent accidental exposure of your buckets. Even if you create a bucket policy that appears to grant public access, AWS will block it until you disable the "Block all public access" option.

![image](https://github.com/user-attachments/assets/bda33815-4550-4b29-b993-e71faee4a8d8)

**IAM Policies vs. Resource Policies**
Understanding the differences between IAM policies and resource (bucket) policies is critical:

**IAM Policies:**
These are attached to users or roles and determine the actions they can perform. They apply only to authenticated AWS users.

**Resource Policies:**
These policies are directly attached to AWS resources such as S3 buckets. They can grant permissions to both authenticated AWS users and anonymous/public users.

#### S3 Static Website Hosting
* S3 for Static Content: Ideal for hosting static files such as HTML, CSS, JavaScript, and media.
* URL Structure: When enabled, S3 provides a URL in the format:
  * http://bucketname.s3-website-<region-name>.amazonaws.com
* Custom Domain Setup: To use your own domain (e.g., example.com), ensure your S3 bucket's name matches your domain name exactly.

#### S3 Pres Signed URLs

* If you need to share a specific file with someone who does not have an AWS account, the bucket's private settings prevent public access.
* a pre-signed URL does not grant new permissions. It merely allows a request to be executed using the IAM user's current permissions.
* If the user lacks access to a particular object, then any pre-signed URL they generate will also fail to access it.

#### S3 Access Points
* Consider an S3 bucket serving multiple stakeholders, such as developers, infrastructure teams, legal, and administrators.
* Each group may require distinct access levels; for example, developers might access specific folders, the infrastructure team may need full access, while legal may only require read-only permissions.
* To manage this complexity, you can create separate access points for each group.
* Each access point acts as a dedicated gateway into the S3 bucket, with its own Amazon Resource Name (ARN) and a set of finely tuned policies

![image](https://github.com/user-attachments/assets/f5f236e8-5c2a-48b3-8e24-c1a2c55e78db)

* Another significant benefit of access points is their capability to enforce network-level restrictions. For example, you can restrict access to the S3 bucket to specific Virtual Private Clouds (VPCs) by managing VPC endpoints via access points.
* When defining access point policies, it is important to note that the initial configuration requires the access point policy to be mirrored in the bucket policy.
* However, to streamline management and reduce redundancy, you can modify the bucket policy to delegate access control directly to the access points.
* This delegation centralizes policy management at the access point level and minimizes the need for frequent updates to the bucket policy.

![image](https://github.com/user-attachments/assets/7c962c79-ae30-49a7-86db-73e027ccb201)

