## S3 (Simple Storage Service)

* S3 (Simple Storage Service) is a highly scalable, available, secure, and high-performance object storage service provided by Amazon Web Services (AWS).
* In simple terms, S3 functions like a cloud-based storage service similar to Dropbox or Google Drive, but with the extensive capabilities and integration of AWS.
* S3 is an object-based storage system, meaning it stores complete objects (files) with their metadata.

  ![image](https://github.com/user-attachments/assets/af9f0498-a8b3-4a84-a756-d88bcc36a9d7)

  * S3 is ideal for storing:
    * Application log files
    * Media assets such as images, videos, and audio files
    * Artifacts generated from CI/CD pipelines

* Buckets
  * Buckets are the containers in S3 where objects (files) are stored. Think of a bucket as a folder that groups related files.
  *  **Bucket name has to be unique across AWS.**

* Objects
  * An object in S3 consists of the file data and its metadata. Each object includes:
    * A key: a unique name for the file.
    * A value: the actual data of the file.
    * Additional properties such as version ID and metadata (if versioning is enabled).
   
![image](https://github.com/user-attachments/assets/ace0ead0-254b-4424-8c7e-8aa7ca1bc3d5)

* Flat File Structure
  * S3 utilizes a flat file structure, meaning there is no inherent concept of nested directories. While the AWS console may visually display folder-like groupings using prefixes, the underlying storage remains flat. For example, uploading files with keys like "music/song_one", "music/song_two", and "music/song_three" creates the illusion of a "music" folder.

![image](https://github.com/user-attachments/assets/ddf53c35-c2fb-4198-b4b6-229645052958)

* Data Durability and Availability
  * When you upload a file to S3, AWS replicates it across multiple servers and availability zones. This replication ensures high durability and availability, protecting your data even if a server or entire availability zone fails.

![image](https://github.com/user-attachments/assets/ec136ae9-1dc7-4b18-a03b-aac950118ec6)

* S3 Restrictions
  * S3 can store an unlimited number of objects.
  * The maximum size for a single object is 5 terabytes.
  * By default, each AWS account can create up to 100 buckets. This limit can be increased up to 1,000 by requesting a service limit increase.

## S3 Storage Classes

* **S3 Standard**
  * S3 Standard is the default storage class for AWS S3. When you upload a file without specifying a storage class, it is automatically stored as S3 Standard.
  * In this class, objects are automatically replicated across at least three Availability Zones (AZs), enabling the system to survive up to two simultaneous AZ failures.
  * This design ensures an impressive durability of 99.999999999% (11 nines).
  * Billed per gigabyte per month.
  * Low latency access with files available in milliseconds.
  * Support for public access (ideal for web application media files).
  * Charges for data egress; uploading data (ingress) is free.

* **S3 Standard-IA (Infrequent Access)**
  * S3 Standard-IA is designed for data that is accessed less frequently while still requiring rapid access when needed.
  * Similar to S3 Standard, it replicates data across at least three Availability Zones to ensure high durability.
  * However, it offers a lower storage cost for infrequently accessed data.
  * Lower per gigabyte storage rates compared to S3 Standard.
  * Maintains low latency for rapid data access.
  * Applies a retrieval fee on each data request along with a per-gigabyte egress charge.
  * Enforces a minimum duration charge of 30 days per object. If an object is deleted before 30 days, you are still charged for the full period.
  * Uses a minimum object size charge of 128 kilobytes (even a 1 KB file is billed as 128 KB).
 
* **S3 One Zone-IA (One Zone Infrequent Access)**
  * S3 One Zone-IA is similar to S3 Standard-IA, but stores data in a single Availability Zone instead of multiple zones, resulting in lower storage costs.
  * This makes it an attractive option for data that is infrequently accessed and does not require the added resiliency of multiple AZ replication.
  * Provides immediate, low latency access.
  * Supports public access similar to other S3 storage classes.
  * Applies charges for egress, retrieval, a minimum duration of 30 days, and a minimum size charge of 128 kilobytes.
  * Lacks multi-AZ replication, meaning that in the event of an AZ failure, your data could become inaccessible.
 
* **S3 Glacier Instant**
  * S3 Glacier Instant is part of the Glacier family and is designed for archiving data that is rarely accessed while providing rapid data retrieval.
  * Low-cost storage optimized for archival data.
  * Retrieval of data in milliseconds.
  * Lower per gigabyte charges compared to S3 Standard.
  * Data egress fees and additional retrieval fees apply.
  * A minimum duration charge of 90 days and a minimum size charge of 128 kilobytes per object.

* **S3 Glacier Flexible**
  * S3 Glacier Flexible is intended for data that is archived and does not require immediate access.
  * Unlike S3 Glacier Instant, objects stored in Glacier Flexible are not available instantly; a retrieval process similar to a "cold start" is necessary.
  * Consequently, direct public access to these objects is not supported.
  * Retrieval fees and a minimum duration charge of 90 days apply.
  * Enforces a minimum size charge of 40 kilobytes per object.
  * Offers three retrieval options based on speed:
    * Expedited (1–5 minutes)
    * Standard (3–5 hours)
    * Bulk (5–12 hours)

* **S3 Glacier Deep Archive**
  *  S3 Glacier Deep Archive provides the most cost-effective storage solution available for AWS S3.
  *  Like Glacier Flexible, objects stored in this class are not immediately available and must go through a retrieval process.
  *  This class is ideal for data that is rarely needed and can tolerate longer retrieval times.
  *  Charges include a per-gigabyte egress fee and a retrieval fee.
  *  A minimum duration charge of 180 days applies, along with a minimum size charge of 40 kilobytes per object.
  *  Retrieval options include:
     * Standard (within 12 hours)
     * Bulk (within 48 hours; the more cost-effective choice if immediate access isn’t critical)
  * Retrieved data is temporarily stored in S3 Standard-IA.

* **S3 Intelligent Tiering**
  * S3 Intelligent Tiering is a smart storage option for workloads with unpredictable access patterns.
  * This class automatically moves data between tiers to optimize storage costs based on changing usage patterns.
  * An additional monitoring and automation fee is applied per 1,000 objects alongside the underlying storage cost.

Choosing the Right Storage Class
* Selecting the appropriate storage class depends on your performance requirements and budget considerations.
* Use the following decision-making process to choose the correct AWS S3 storage class:

Determine if immediate access (within milliseconds) is necessary.
 * If yes, consider:
   * Frequent access: Choose S3 Standard.
   * Infrequent access:
     * Multi-AZ resilience needed: Choose S3 Standard-IA.
     * Single-AZ storage is sufficient: Choose S3 One Zone-IA.
 * If immediate access is not required:
   * For very rarely accessed data: Choose S3 Glacier Deep Archive.
   * For archival data with occasional access needs: Choose S3 Glacier Flexible.
  
 ![image](https://github.com/user-attachments/assets/7d1dbccd-a8c1-4450-b90c-da2a443c7ad2)



 
